{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    plt.figure(figsize=(4,4));\n",
    "    plt.imshow(img, cmap = \"gray\");\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_lbl(idx):\n",
    "    a = ['airplane',\n",
    "         'automobile',\n",
    "         'bird',\n",
    "         'cat',\n",
    "         'deer',\n",
    "         'dog',\n",
    "         'frog',\n",
    "         'horse',\n",
    "         'ship',\n",
    "         'truck']\n",
    "    return a[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automobile'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_to_lbl(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_3_channels = transforms.Lambda(\n",
    "        lambda x: torch.cat([x, x, x], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = T.Compose([\n",
    "    T.RandomCrop((28,28)),\n",
    "    T.Grayscale(),\n",
    "    T.ToTensor(),\n",
    "    T.Lambda(lambda x: x.view(x.shape[1]**2)) # reshaping for our input shape\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torchvision.datasets.CIFAR10(root = \"data/\", \n",
    "                                  train = True, \n",
    "                                  transform  = train_tfms, \n",
    "                                  target_transform = None, \n",
    "                                  download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lbl = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horse'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(np.array(img).reshape(28,28))\n",
    "map_to_lbl(lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(ds,\n",
    "                          batch_size=50000,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0553)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4759)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(batch[0], dtype= np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(1 / (a.var(axis=0) * 2)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47594396991586485"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
